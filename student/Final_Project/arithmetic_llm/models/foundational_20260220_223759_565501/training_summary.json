{
  "total_epochs": 10,
  "total_steps": 112500,
  "final_train_loss": 0.46725746989250183,
  "final_val_loss": 0.4617712199687958,
  "best_val_loss": 0.4617712199687958,
  "model_config": {
    "d_model": 256,
    "nhead": 8,
    "num_layers": 6,
    "dim_feedforward": 1024,
    "dropout": 0.1,
    "max_seq_length": 512,
    "vocab_size": 276
  },
  "training_config": {
    "learning_rate": 0.0001,
    "batch_size": 16,
    "num_epochs": 10,
    "warmup_steps": 1000,
    "gradient_clip": 1.0,
    "save_every": 1000,
    "eval_every": 500,
    "device": "cuda",
    "lora_config": null
  },
  "tokenizer_vocab_size": 276
}