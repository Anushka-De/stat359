{
  "cells": [
    {
      "cell_type": "raw",
      "id": "3f9655a7",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        },
        "id": "3f9655a7"
      },
      "source": [
        "---\n",
        "title: \"Assignment 3: Neural Models for Sentiment Classification\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-title: Contents\n",
        "    toc-depth: 4\n",
        "    self-contained: true\n",
        "    number-sections: false\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e43e1df",
      "metadata": {
        "id": "6e43e1df"
      },
      "source": [
        "### <font color='blue'> Due 11:59pm, Monday Feb 12th 2026</font>\n",
        "\n",
        "**Purpose / learning goals:**\n",
        "- Practice training neural models in PyTorch with emphasis on optimizers, regularization, and learning-rate scheduling to meet a performance threshold.\n",
        "- Use sentiment classification as a downstream task to compare classical neural baselines with fine-tuned pretrained LLMs (BERT/GPT).\n",
        "\n",
        "**Runtime / setup notes:**\n",
        "- This assignment does not require a GPU to train the models. Using a GPU (or Apple MPS) will usually speed up training for the transformer models.\n",
        "\n",
        "In this assignment, you will:\n",
        "- Implement MLP and LSTM classifiers (your code)\n",
        "- Run provided scripts for RNN, GRU, BERT, and GPT (for comparison)\n",
        "\n",
        "**Implementation format:** Task 1 and Task 2 must be implemented as Python scripts (not notebooks). The open-ended questions are answered in a notebook.\n",
        "\n",
        "To motivate the transformer architecture, scripts are provided for pretrained state-of-the-art models such as **GPT** (decoder-only) and **BERT** (encoder-only). You should run these scripts yourself to obtain results for comparison and reflection.\n",
        "\n",
        "*Please read the `README.md` file before proceeding.*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e243326",
      "metadata": {
        "id": "1e243326"
      },
      "source": [
        "##  Sentiment Classification: Classical Nets vs. LLMs\n",
        "\n",
        "Sentiment classification is a common **downstream task** for evaluating how well pretrained LLMs adapt to a domain via fine-tuning, compared against classical neural baselines.\n",
        "\n",
        "In this assignment, you'll explore how different neural architectures perform on sentiment classification:\n",
        "\n",
        "- **Classical approaches:** MLP, RNN, LSTM, GRU (using static FastText embeddings)\n",
        "- **Pretrained LLMs:** BERT and GPT (fine-tuned using Hugging Face Transformers)\n",
        "\n",
        "You will implement MLP and LSTM yourself; scripts are provided for the remaining models.\n",
        "\n",
        "Detailed requirements for your implementations are listed in **Your Tasks** below.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d347c96",
      "metadata": {
        "id": "9d347c96"
      },
      "source": [
        "##  Dataset: Financial PhraseBank\n",
        "\n",
        "This assignment uses the **Financial PhraseBank** dataset, developed by  \n",
        "Mika V. M√§ntyl√§, Graziella Linders, Tanja Suominen, and Miikka Kuutila.\n",
        "\n",
        "- üìÇ Dataset homepage: [Hugging Face ‚Äì Financial_PhraseBank](https://huggingface.co/datasets/takala/financial_phrasebank)  \n",
        "- üìÑ Original paper:  \n",
        "  P. Malo, A. Sinha, et al. (2014). [*‚ÄúGood Debt or Bad Debt: Detecting Semantic Orientations in Economic Texts‚Äù*](https://arxiv.org/pdf/1307.5336)\n",
        "\n",
        "You can load and preview the dataset using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Anushka-De/stat359.git"
      ],
      "metadata": {
        "id": "kPP2CDEVJrZK",
        "outputId": "c2f1180e-4f43-47e4-c2b0-8bc6c8b67273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "kPP2CDEVJrZK",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stat359'...\n",
            "remote: Enumerating objects: 196, done.\u001b[K\n",
            "remote: Counting objects: 100% (104/104), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 196 (delta 78), reused 51 (delta 40), pack-reused 92 (from 1)\u001b[K\n",
            "Receiving objects: 100% (196/196), 1.75 MiB | 4.72 MiB/s, done.\n",
            "Resolving deltas: 100% (114/114), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stat359/student/Assignment_3\n",
        "!ls"
      ],
      "metadata": {
        "id": "JmH8P93LJtga",
        "outputId": "2f60e961-176e-4350-e749-31704974f762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "JmH8P93LJtga",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stat359/student/Assignment_3\n",
            "handout.html\t      train_sentiment_bert_classifier.py\n",
            "handout.ipynb\t      train_sentiment_gpt_classifier.py\n",
            "open_questions.ipynb  train_sentiment_gru_classifier.py\n",
            "README.md\t      train_sentiment_rnn_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip -q install \"datasets<4.0.0\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOb0jBZy35Cz",
        "outputId": "af3fcb9f-5655-4188-96ef-b9878da7de02"
      },
      "id": "lOb0jBZy35Cz",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/491.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy pandas gensim torch scikit-learn matplotlib ipywidgets nltk tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fR_RM9R5T7L",
        "outputId": "65fbc072-ddec-4045-e3ef-a109d7a526e7"
      },
      "id": "-fR_RM9R5T7L",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"\\n========== Loading Dataset ==========\")\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('financial_phrasebank', 'sentences_50agree', trust_remote_code=True)\n",
        "print(\"Dataset loaded. Example:\", dataset['train'][:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-4FZj7Q760p",
        "outputId": "97077f92-460d-4e20-fa86-30655afd1774"
      },
      "id": "V-4FZj7Q760p",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========== Loading Dataset ==========\n",
            "Dataset loaded. Example: {'sentence': ['According to Gran , the company has no plans to move all production to Russia , although that is where the company is growing .', 'Technopolis plans to develop in stages an area of no less than 100,000 square meters in order to host companies working in computer technologies and telecommunications , the statement said .', 'The international electronic industry company Elcoteq has laid off tens of employees from its Tallinn facility ; contrary to earlier layoffs the company contracted the ranks of its office workers , the daily Postimees reported .', 'With the new production plant the company would increase its capacity to meet the expected increase in demand and would improve the use of raw materials and therefore increase the production profitability .', \"According to the company 's updated strategy for the years 2009-2012 , Basware targets a long-term net sales growth in the range of 20 % -40 % with an operating profit margin of 10 % -20 % of net sales .\"], 'label': [1, 1, 0, 2, 2]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d51c574",
      "metadata": {
        "id": "9d51c574"
      },
      "source": [
        "###  Dataset Description\n",
        "\n",
        "The dataset consists of **4,840 English sentences** extracted from financial news articles.  \n",
        "Each sentence is labeled as **positive**, **neutral**, or **negative**, with annotations provided by 5 to 8 human annotators to ensure labeling consistency.  \n",
        "\n",
        "This assignment uses the `'sentences_50agree'` subset, where at least 50% of annotators agreed on the sentiment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da05e0ad",
      "metadata": {
        "id": "da05e0ad"
      },
      "source": [
        "###  Class Imbalance\n",
        "\n",
        "The dataset has an **imbalanced class distribution**:\n",
        "\n",
        "| Sentiment | Count |\n",
        "|-----------|-------|\n",
        "| Negative  | 604   |\n",
        "| Neutral   | 2879  |\n",
        "| Positive  | 1363  |\n",
        "\n",
        "For dealing with imbalanced dataset:\n",
        "\n",
        "- **Accuracy** can be misleading in this setting.\n",
        "- You must use `class_weight` in your loss function (e.g., `nn.CrossEntropyLoss(weight=...)`) to mitigate the imbalance.\n",
        "- The primary evaluation metric will be the **macro-averaged F1 score**, which treats all classes equally regardless of frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccf5ce4c",
      "metadata": {
        "id": "ccf5ce4c"
      },
      "source": [
        "### Train/Validation/Test Splits\n",
        "\n",
        "The dataset does **not** come with predefined splits.\n",
        "\n",
        "You must split it yourself using **stratified sampling** to preserve class proportions in each subset.\n",
        "\n",
        "For a fair comparison and to stay consistent with the other model scripts, use the following split procedure:\n",
        "\n",
        "- First, create a **test set (15%)** and a **train+validation set (85%)** using stratified sampling on the original labels.\n",
        "- Then, split the **train+validation set** into **training (85%)** and **validation (15%)** using stratified sampling on the train+validation labels.\n",
        "- Use a fixed random seed (e.g., 42) so results are reproducible.\n",
        "\n",
        "This ensures consistent and representative evaluation, especially in the presence of class imbalance."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Validation/Test Splits (stratified)\n",
        "SEED = 42\n",
        "\n",
        "# If the dataset is a DatasetDict with only \"train\", split it:\n",
        "full = dataset[\"train\"]  # contains columns like \"sentence\" and \"label\"\n",
        "\n",
        "# 1) Test = 15%, Train+Val = 85% (stratified)\n",
        "tmp = full.train_test_split(\n",
        "    test_size=0.15,\n",
        "    seed=SEED,\n",
        "    stratify_by_column=\"label\"\n",
        ")\n",
        "trainval_ds = tmp[\"train\"]\n",
        "test_ds = tmp[\"test\"]\n",
        "\n",
        "# 2) From Train+Val, Validation = 15%, Training = 85% (stratified)\n",
        "tmp2 = trainval_ds.train_test_split(\n",
        "    test_size=0.15,\n",
        "    seed=SEED,\n",
        "    stratify_by_column=\"label\"\n",
        ")\n",
        "train_ds = tmp2[\"train\"]\n",
        "val_ds = tmp2[\"test\"]\n",
        "\n",
        "print(len(train_ds), len(val_ds), len(test_ds))\n",
        "import collections\n",
        "\n",
        "def show_stats(ds, name):\n",
        "    labels = ds[\"label\"]\n",
        "    counter = collections.Counter(labels)\n",
        "    total = len(labels)\n",
        "\n",
        "    print(f\"\\n{name} ‚Äî total: {total}\")\n",
        "    for k in sorted(counter):\n",
        "        print(f\"  class {k}: {counter[k]} ({counter[k]/total:.3%})\")\n",
        "\n",
        "show_stats(train_ds, \"TRAIN\")\n",
        "show_stats(val_ds, \"VALIDATION\")\n",
        "show_stats(test_ds, \"TEST\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_2_7SybBy86",
        "outputId": "21793f00-e7a8-45c3-a28a-fe865af8383a"
      },
      "id": "-_2_7SybBy86",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3501 618 727\n",
            "\n",
            "TRAIN ‚Äî total: 3501\n",
            "  class 0: 436 (12.454%)\n",
            "  class 1: 2080 (59.412%)\n",
            "  class 2: 985 (28.135%)\n",
            "\n",
            "VALIDATION ‚Äî total: 618\n",
            "  class 0: 77 (12.460%)\n",
            "  class 1: 367 (59.385%)\n",
            "  class 2: 174 (28.155%)\n",
            "\n",
            "TEST ‚Äî total: 727\n",
            "  class 0: 91 (12.517%)\n",
            "  class 1: 432 (59.422%)\n",
            "  class 2: 204 (28.061%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05b696bf",
      "metadata": {
        "id": "05b696bf"
      },
      "source": [
        "## Your Tasks\n",
        "\n",
        "Before you begin, please follow these best practices in your implementation:\n",
        "\n",
        "- Set **random seeds** to ensure reproducibility  \n",
        "- Use `torch.save()` to save your **best-performing model**  \n",
        "- Modularize your code into **reusable functions or classes**\n",
        "\n",
        "You are encouraged to experiment with different **neural network architectures**, **hyperparameters**, **optimizers**, **regularization** (e.g., dropout, weight decay), and **learning-rate scheduling**, as long as your final model meets the required **macro F1 score threshold** for each task.\n",
        "\n",
        "**Implementation format:** Task 1 and Task 2 must be implemented as Python scripts (not notebooks). Name them as specified below.\n",
        "\n",
        "### Task 1: MLP with Mean-Pooled FastText Sentence Embedding **(25 points)**\n",
        "\n",
        "Create a script named `train_sentiment_mlp_classifier.py` and complete the following:\n",
        "\n",
        "- Load **pretrained FastText embeddings** using Gensim.\n",
        "- Tokenize each sentence and compute the **mean of its word vectors** to obtain a fixed-size (300-dimensional) sentence embedding.\n",
        "- Use a **Multi-Layer Perceptron (MLP)** to classify the sentence embedding.\n",
        "- Handle **class imbalance** using `nn.CrossEntropyLoss(weight=...)`.\n",
        "- Track and report the following metrics:\n",
        "  - **Loss**\n",
        "  - **Accuracy**\n",
        "  - **Macro F1 Score**\n",
        "\n",
        "#### Performance Requirement:\n",
        "Your model must achieve a **Test Macro F1 Score >= 0.65**\n",
        "\n",
        "### Task 2: LSTM with Padded FastText Word Vectors **(25 points)**\n",
        "\n",
        "Create a script named `train_sentiment_lstm_classifier.py` and complete the following:\n",
        "\n",
        "- Tokenize each sentence into word tokens and retrieve the corresponding **FastText word vectors**.\n",
        "- **Pad or truncate** each sentence to exactly **32 tokens**.\n",
        "- Construct a tensor of shape **(32, 300)** for each sentence (300 = embedding dimension).\n",
        "- **Do not use** `nn.Embedding`; instead, **precompute and batch** the word vectors directly.\n",
        "- Pass the sequences into an **LSTM model** and classify using the **final hidden state**.\n",
        "- Use `nn.CrossEntropyLoss(weight=...)` and evaluate using **macro-averaged F1 score**.\n",
        "\n",
        "#### Performance Requirement:\n",
        "Your model must achieve a **Test Macro F1 Score >= 0.70**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_sentiment_mlp_classifier.py\n",
        "#!/usr/bin/env python3\n",
        "# train_sentiment_mlp_classifier.py\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from datasets import load_dataset\n",
        "import gensim.downloader as api\n",
        "\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Config\n",
        "# -----------------------------\n",
        "SEED = 42\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "MIN_EPOCHS = 30          # must train at least 30 epochs\n",
        "MAX_EPOCHS = 60          # you may train longer\n",
        "PATIENCE = 10            # early stop patience (only active after epoch >= MIN_EPOCHS)\n",
        "\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "HIDDEN_DIM = 256\n",
        "DROPOUT = 0.3\n",
        "EMB_DIM = 300\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "ART_DIR = \"artifacts/task1\"\n",
        "CKPT_DIR = \"checkpoints\"\n",
        "BEST_PATH = os.path.join(CKPT_DIR, \"best_mlp_fasttext.pt\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Utilities\n",
        "# -----------------------------\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "_token_re = re.compile(r\"[A-Za-z]+(?:'[A-Za-z]+)?|[0-9]+\")  # simple tokenizer\n",
        "\n",
        "\n",
        "def tokenize(text: str):\n",
        "    return _token_re.findall(text.lower())\n",
        "\n",
        "\n",
        "def mean_pool_fasttext(tokens, ft_model):\n",
        "    \"\"\"Mean of word vectors (300-d). If no known tokens, return zeros.\"\"\"\n",
        "    vecs = []\n",
        "    for w in tokens:\n",
        "        if w in ft_model:\n",
        "            vecs.append(ft_model[w])\n",
        "    if len(vecs) == 0:\n",
        "        return np.zeros((EMB_DIM,), dtype=np.float32)\n",
        "    return np.mean(np.stack(vecs, axis=0), axis=0).astype(np.float32)\n",
        "\n",
        "\n",
        "def save_curve_plot(train_vals, val_vals, ylabel, title, outpath):\n",
        "    epochs = np.arange(1, len(train_vals) + 1)\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, train_vals, marker=\"o\", label=\"train\")\n",
        "    plt.plot(epochs, val_vals, marker=\"o\", label=\"val\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath, dpi=200)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def save_confusion_matrix(y_true, y_pred, class_names, outpath):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    disp.plot(ax=ax, values_format=\"d\", colorbar=True)\n",
        "    ax.set_title(\"Confusion Matrix (Test)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(outpath, dpi=200)\n",
        "    plt.close()\n",
        "    return cm\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_all(model, loader, device):\n",
        "    model.eval()\n",
        "    all_preds, all_y = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(device)\n",
        "        logits = model(xb)\n",
        "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_y.append(yb.numpy())\n",
        "    return np.concatenate(all_y), np.concatenate(all_preds)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset + Model\n",
        "# -----------------------------\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, ft_model):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.ft_model = ft_model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sent = self.texts[idx]\n",
        "        y = int(self.labels[idx])\n",
        "        tokens = tokenize(sent)\n",
        "        x = mean_pool_fasttext(tokens, self.ft_model)  # (300,)\n",
        "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "class MLPClassifier(nn.Module):\n",
        "    def __init__(self, in_dim=300, hidden_dim=256, num_classes=3, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    all_preds, all_y = [], []\n",
        "    for xb, yb in loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        all_preds.append(preds.cpu().numpy())\n",
        "        all_y.append(yb.cpu().numpy())\n",
        "\n",
        "    y_true = np.concatenate(all_y)\n",
        "    y_pred = np.concatenate(all_preds)\n",
        "\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    macro_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "    return float(np.mean(losses)), acc, macro_f1\n",
        "\n",
        "\n",
        "def compute_class_weights(labels, num_classes=3):\n",
        "    counts = np.bincount(labels, minlength=num_classes).astype(np.float32)\n",
        "    weights = 1.0 / np.maximum(counts, 1.0)\n",
        "    weights = weights * (num_classes / weights.sum())  # normalize (optional)\n",
        "    return torch.tensor(weights, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    set_seed(SEED)\n",
        "    os.makedirs(ART_DIR, exist_ok=True)\n",
        "    os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "    # 1) Load dataset\n",
        "    dataset = load_dataset(\"financial_phrasebank\", \"sentences_50agree\", trust_remote_code=True)\n",
        "    full = dataset[\"train\"]\n",
        "\n",
        "    # 2) Stratified Train/Val/Test split\n",
        "    tmp = full.train_test_split(test_size=0.15, seed=SEED, stratify_by_column=\"label\")\n",
        "    trainval = tmp[\"train\"]\n",
        "    test_ds_hf = tmp[\"test\"]\n",
        "\n",
        "    tmp2 = trainval.train_test_split(test_size=0.15, seed=SEED, stratify_by_column=\"label\")\n",
        "    train_ds_hf = tmp2[\"train\"]\n",
        "    val_ds_hf = tmp2[\"test\"]\n",
        "\n",
        "    # 3) Load pretrained FastText via Gensim (downloads on first run)\n",
        "    ft = api.load(\"fasttext-wiki-news-subwords-300\")\n",
        "\n",
        "    # 4) Wrap into torch datasets/loaders\n",
        "    train_ds = SentimentDataset(train_ds_hf[\"sentence\"], train_ds_hf[\"label\"], ft)\n",
        "    val_ds = SentimentDataset(val_ds_hf[\"sentence\"], val_ds_hf[\"label\"], ft)\n",
        "    test_ds = SentimentDataset(test_ds_hf[\"sentence\"], test_ds_hf[\"label\"], ft)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # 5) Model + class-weighted loss\n",
        "    class_w = compute_class_weights(np.array(train_ds_hf[\"label\"]), num_classes=3).to(DEVICE)\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_w)\n",
        "\n",
        "    model = MLPClassifier(in_dim=EMB_DIM, hidden_dim=HIDDEN_DIM, num_classes=3, dropout=DROPOUT).to(DEVICE)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    # 6) Train loop + metric tracking + checkpoint + early stopping after epoch 30\n",
        "    history = {\n",
        "        \"train_loss\": [], \"train_acc\": [], \"train_f1\": [],\n",
        "        \"val_loss\": [], \"val_acc\": [], \"val_f1\": []\n",
        "    }\n",
        "\n",
        "    best_val_f1 = -1.0\n",
        "    best_epoch = -1\n",
        "    epochs_since_improve = 0\n",
        "\n",
        "    for epoch in range(1, MAX_EPOCHS + 1):\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        all_preds, all_y = [], []\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_losses.append(loss.item())\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "            all_preds.append(preds.detach().cpu().numpy())\n",
        "            all_y.append(yb.detach().cpu().numpy())\n",
        "\n",
        "        y_true = np.concatenate(all_y)\n",
        "        y_pred = np.concatenate(all_preds)\n",
        "\n",
        "        train_loss = float(np.mean(train_losses))\n",
        "        train_acc = accuracy_score(y_true, y_pred)\n",
        "        train_f1 = f1_score(y_true, y_pred, average=\"macro\")\n",
        "\n",
        "        val_loss, val_acc, val_f1 = evaluate(model, val_loader, criterion, DEVICE)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch:02d}/{MAX_EPOCHS} | \"\n",
        "            f\"train loss {train_loss:.4f} acc {train_acc:.4f} f1 {train_f1:.4f} | \"\n",
        "            f\"val loss {val_loss:.4f} acc {val_acc:.4f} f1 {val_f1:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Save best model by validation macro-F1\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            best_epoch = epoch\n",
        "            epochs_since_improve = 0\n",
        "            torch.save(\n",
        "                {\n",
        "                    \"model_state_dict\": model.state_dict(),\n",
        "                    \"best_val_f1\": best_val_f1,\n",
        "                    \"best_epoch\": best_epoch,\n",
        "                    \"class_weights\": class_w.detach().cpu(),\n",
        "                    \"history\": history,\n",
        "                },\n",
        "                BEST_PATH,\n",
        "            )\n",
        "        else:\n",
        "            epochs_since_improve += 1\n",
        "\n",
        "        # Early stopping ONLY allowed after epoch >= MIN_EPOCHS\n",
        "        if epoch >= MIN_EPOCHS and epochs_since_improve >= PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch} (best epoch {best_epoch}).\")\n",
        "            break\n",
        "\n",
        "    # 7) Save plots to disk\n",
        "    save_curve_plot(history[\"train_loss\"], history[\"val_loss\"],\n",
        "                    ylabel=\"Loss\", title=\"Loss vs Epochs\",\n",
        "                    outpath=os.path.join(ART_DIR, \"loss_vs_epoch.png\"))\n",
        "\n",
        "    save_curve_plot(history[\"train_acc\"], history[\"val_acc\"],\n",
        "                    ylabel=\"Accuracy\", title=\"Accuracy vs Epochs\",\n",
        "                    outpath=os.path.join(ART_DIR, \"acc_vs_epoch.png\"))\n",
        "\n",
        "    save_curve_plot(history[\"train_f1\"], history[\"val_f1\"],\n",
        "                    ylabel=\"Macro F1\", title=\"Macro F1 vs Epochs\",\n",
        "                    outpath=os.path.join(ART_DIR, \"macro_f1_vs_epoch.png\"))\n",
        "\n",
        "    # 8) Final test eval with best checkpoint + confusion matrix\n",
        "    ckpt = torch.load(BEST_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(ckpt[\"model_state_dict\"])\n",
        "\n",
        "    test_loss, test_acc, test_f1 = evaluate(model, test_loader, criterion, DEVICE)\n",
        "    print(\"\\nBEST VAL MACRO-F1:\", ckpt[\"best_val_f1\"], \"at epoch\", ckpt[\"best_epoch\"])\n",
        "    print(f\"TEST | loss {test_loss:.4f} acc {test_acc:.4f} macro-f1 {test_f1:.4f}\")\n",
        "    print(\"Saved best model to:\", BEST_PATH)\n",
        "\n",
        "    y_true_test, y_pred_test = predict_all(model, test_loader, DEVICE)\n",
        "\n",
        "    # If your assignment defines a label order, match it here.\n",
        "    class_names = [\"negative\", \"neutral\", \"positive\"]\n",
        "    cm = save_confusion_matrix(\n",
        "        y_true_test, y_pred_test,\n",
        "        class_names=class_names,\n",
        "        outpath=os.path.join(ART_DIR, \"confusion_matrix_test.png\")\n",
        "    )\n",
        "    np.savetxt(os.path.join(ART_DIR, \"confusion_matrix_test.txt\"), cm, fmt=\"%d\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRIiLH9mFWyk",
        "outputId": "78baf244-7b25-4c0d-f287-4d741d59136c"
      },
      "id": "MRIiLH9mFWyk",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train_sentiment_mlp_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_sentiment_mlp_classifier.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDBEPzk26FXY",
        "outputId": "544e42aa-fcba-4f61-da21-fe365ec47311"
      },
      "id": "WDBEPzk26FXY",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01/60 | train loss 1.0588 acc 0.4616 f1 0.3999 | val loss 1.0470 acc 0.5210 f1 0.3647\n",
            "Epoch 02/60 | train loss 0.9860 acc 0.5573 f1 0.4415 | val loss 0.9518 acc 0.5372 f1 0.4142\n",
            "Epoch 03/60 | train loss 0.9098 acc 0.5807 f1 0.4862 | val loss 0.9117 acc 0.5890 f1 0.5029\n",
            "Epoch 04/60 | train loss 0.8589 acc 0.6073 f1 0.5442 | val loss 0.8612 acc 0.5324 f1 0.5065\n",
            "Epoch 05/60 | train loss 0.8131 acc 0.6281 f1 0.5655 | val loss 0.8115 acc 0.6392 f1 0.5519\n",
            "Epoch 06/60 | train loss 0.7705 acc 0.6524 f1 0.5995 | val loss 0.7748 acc 0.6634 f1 0.5924\n",
            "Epoch 07/60 | train loss 0.7378 acc 0.6672 f1 0.6209 | val loss 0.7555 acc 0.6893 f1 0.6297\n",
            "Epoch 08/60 | train loss 0.7131 acc 0.6695 f1 0.6265 | val loss 0.7326 acc 0.6909 f1 0.6268\n",
            "Epoch 09/60 | train loss 0.6724 acc 0.6858 f1 0.6458 | val loss 0.7319 acc 0.6327 f1 0.5855\n",
            "Epoch 10/60 | train loss 0.6705 acc 0.6935 f1 0.6549 | val loss 0.7168 acc 0.6343 f1 0.6060\n",
            "Epoch 11/60 | train loss 0.6444 acc 0.7067 f1 0.6704 | val loss 0.6902 acc 0.6634 f1 0.6228\n",
            "Epoch 12/60 | train loss 0.6508 acc 0.6898 f1 0.6496 | val loss 0.7659 acc 0.7055 f1 0.6550\n",
            "Epoch 13/60 | train loss 0.6249 acc 0.7095 f1 0.6717 | val loss 0.6827 acc 0.7006 f1 0.6667\n",
            "Epoch 14/60 | train loss 0.6194 acc 0.7144 f1 0.6778 | val loss 0.7043 acc 0.6861 f1 0.6580\n",
            "Epoch 15/60 | train loss 0.6011 acc 0.7247 f1 0.6923 | val loss 0.6874 acc 0.6472 f1 0.6159\n",
            "Epoch 16/60 | train loss 0.5874 acc 0.7184 f1 0.6841 | val loss 0.7135 acc 0.7120 f1 0.6500\n",
            "Epoch 17/60 | train loss 0.5808 acc 0.7395 f1 0.7075 | val loss 0.6807 acc 0.7023 f1 0.6575\n",
            "Epoch 18/60 | train loss 0.5606 acc 0.7406 f1 0.7103 | val loss 0.6846 acc 0.6780 f1 0.6284\n",
            "Epoch 19/60 | train loss 0.5522 acc 0.7384 f1 0.7074 | val loss 0.6908 acc 0.6812 f1 0.6503\n",
            "Epoch 20/60 | train loss 0.5428 acc 0.7449 f1 0.7192 | val loss 0.6740 acc 0.6764 f1 0.6327\n",
            "Epoch 21/60 | train loss 0.5196 acc 0.7598 f1 0.7334 | val loss 0.7043 acc 0.7217 f1 0.6764\n",
            "Epoch 22/60 | train loss 0.5234 acc 0.7544 f1 0.7270 | val loss 0.6777 acc 0.6845 f1 0.6536\n",
            "Epoch 23/60 | train loss 0.5070 acc 0.7672 f1 0.7376 | val loss 0.6867 acc 0.6521 f1 0.6252\n",
            "Epoch 24/60 | train loss 0.5023 acc 0.7646 f1 0.7360 | val loss 0.7519 acc 0.7071 f1 0.6672\n",
            "Epoch 25/60 | train loss 0.4991 acc 0.7715 f1 0.7449 | val loss 0.7027 acc 0.6699 f1 0.6441\n",
            "Epoch 26/60 | train loss 0.4835 acc 0.7778 f1 0.7530 | val loss 0.7029 acc 0.7071 f1 0.6713\n",
            "Epoch 27/60 | train loss 0.4645 acc 0.7866 f1 0.7605 | val loss 0.7187 acc 0.7217 f1 0.6716\n",
            "Epoch 28/60 | train loss 0.4732 acc 0.7826 f1 0.7544 | val loss 0.7194 acc 0.7120 f1 0.6697\n",
            "Epoch 29/60 | train loss 0.4461 acc 0.7963 f1 0.7730 | val loss 0.7444 acc 0.6990 f1 0.6671\n",
            "Epoch 30/60 | train loss 0.4438 acc 0.8001 f1 0.7782 | val loss 0.7277 acc 0.7233 f1 0.6728\n",
            "Epoch 31/60 | train loss 0.4365 acc 0.7986 f1 0.7755 | val loss 0.7814 acc 0.7233 f1 0.6827\n",
            "Epoch 32/60 | train loss 0.4235 acc 0.8058 f1 0.7831 | val loss 0.7566 acc 0.7443 f1 0.6959\n",
            "Epoch 33/60 | train loss 0.4244 acc 0.8121 f1 0.7917 | val loss 0.8515 acc 0.7282 f1 0.6888\n",
            "Epoch 34/60 | train loss 0.4088 acc 0.8169 f1 0.7952 | val loss 0.7440 acc 0.7152 f1 0.6706\n",
            "Epoch 35/60 | train loss 0.4077 acc 0.8126 f1 0.7894 | val loss 0.8170 acc 0.7411 f1 0.6855\n",
            "Epoch 36/60 | train loss 0.3834 acc 0.8338 f1 0.8148 | val loss 0.8295 acc 0.7557 f1 0.7071\n",
            "Epoch 37/60 | train loss 0.3816 acc 0.8260 f1 0.8093 | val loss 0.7552 acc 0.7104 f1 0.6734\n",
            "Epoch 38/60 | train loss 0.4100 acc 0.8123 f1 0.7912 | val loss 0.8030 acc 0.7201 f1 0.6819\n",
            "Epoch 39/60 | train loss 0.3744 acc 0.8323 f1 0.8124 | val loss 0.7741 acc 0.7233 f1 0.6788\n",
            "Epoch 40/60 | train loss 0.3672 acc 0.8360 f1 0.8189 | val loss 0.7904 acc 0.7184 f1 0.6687\n",
            "Epoch 41/60 | train loss 0.3624 acc 0.8295 f1 0.8085 | val loss 0.8066 acc 0.7298 f1 0.6799\n",
            "Epoch 42/60 | train loss 0.3430 acc 0.8566 f1 0.8377 | val loss 0.8128 acc 0.7411 f1 0.7017\n",
            "Epoch 43/60 | train loss 0.3373 acc 0.8526 f1 0.8356 | val loss 0.8159 acc 0.7346 f1 0.6941\n",
            "Epoch 44/60 | train loss 0.3204 acc 0.8598 f1 0.8432 | val loss 0.8836 acc 0.7395 f1 0.6873\n",
            "Epoch 45/60 | train loss 0.3215 acc 0.8575 f1 0.8431 | val loss 0.9507 acc 0.7411 f1 0.6944\n",
            "Epoch 46/60 | train loss 0.3071 acc 0.8683 f1 0.8534 | val loss 0.8377 acc 0.7362 f1 0.6938\n",
            "Early stopping at epoch 46 (best epoch 36).\n",
            "\n",
            "BEST VAL MACRO-F1: 0.7071446970077107 at epoch 36\n",
            "TEST | loss 0.6715 acc 0.7579 macro-f1 0.7151\n",
            "Saved best model to: checkpoints/best_mlp_fasttext.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"artifacts/task1/loss_vs_epoch.png\")\n",
        "files.download(\"artifacts/task1/acc_vs_epoch.png\")\n",
        "files.download(\"artifacts/task1/macro_f1_vs_epoch.png\")\n",
        "files.download(\"artifacts/task1/confusion_matrix_test.png\")\n",
        "files.download(\"checkpoints/best_mlp_fasttext.pt\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f6ZqgqPOJ2X4",
        "outputId": "dc3ee060-4580-41dc-d3e2-95a20ba4db05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "id": "f6ZqgqPOJ2X4",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d683fd47-b02a-4b78-bf87-5b7d6d8ad8ea\", \"loss_vs_epoch.png\", 84916)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6e9ef7c1-415e-4536-897c-244fa6a3fbcb\", \"acc_vs_epoch.png\", 95305)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb8d1317-e1e0-45b1-ab74-94de10c8a3a6\", \"macro_f1_vs_epoch.png\", 79804)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5767fb18-7c94-4bec-932d-8046c2433e0a\", \"confusion_matrix_test.png\", 61446)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7e86c09f-3cb5-4ff4-be93-25229b8292e8\", \"best_mlp_fasttext.pt\", 580179)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1511ab5",
      "metadata": {
        "id": "f1511ab5"
      },
      "source": [
        "###  Evaluation Requirements **(10 points)**\n",
        "\n",
        "For **both models (MLP and LSTM)**, you must:\n",
        "\n",
        "- Train for **at least 30 epochs**. You may train longer and select the best checkpoint based on validation performance (early stopping is allowed **after** epoch 30).\n",
        "- Track and plot the following metrics for **both training and validation** sets:\n",
        "  - **Loss vs. Epochs**\n",
        "  - **Accuracy vs. Epochs**\n",
        "  - **Macro F1 Score vs. Epochs**\n",
        "\n",
        "Plotting both training and validation curves helps you identify potential issues like **underfitting** or **overfitting**.\n",
        "\n",
        "- After training, evaluate your model on the **test set** and report the **confusion matrix**.\n",
        "- Save plots (training/validation curves and confusion matrix) to disk from your **.py scripts** so they can be embedded in `open_questions.ipynb`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c6bc92",
      "metadata": {
        "id": "b3c6bc92"
      },
      "source": [
        "## Provided Models (Required) **(12 points)**\n",
        "\n",
        "The following scripts are provided to support comparison between classical baselines and fine-tuned LLMs:\n",
        "\n",
        "- **`train_sentiment_rnn_classifier.py`** - Sentiment classifier using a basic RNN architecture  \n",
        "- **`train_sentiment_gru_classifier.py`** - Sentiment classifier using a GRU architecture  \n",
        "- **`train_sentiment_bert_classifier.py`** - Sentiment classifier using a BERT-based model  \n",
        "- **`train_sentiment_gpt_classifier.py`** - Sentiment classifier using a GPT-based model  \n",
        "\n",
        "You must run these models and include their results in your analysis (metrics, plots, and a brief comparison). BERT and GPT are pretrained LLMs that you will **fine-tune** for classification using these scripts. These scripts are **not** submissions and may use different training settings (e.g., fewer epochs).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1293a37",
      "metadata": {
        "id": "c1293a37"
      },
      "source": [
        "## Open-Ended Reflection Questions **(23 points)**\n",
        "\n",
        "After completing your implementations and running all provided scripts, in the notebook named `open_questions.ipynb` to address the following. You may **Include plots** from your training scripts in the notebook output to justify your answers.\n",
        "\n",
        "### 1. Training Dynamics\n",
        "*Focus on your MLP and LSTM implementations*\n",
        "\n",
        "- Did your models show signs of **overfitting** or **underfitting**? What architectural or training changes could address this?\n",
        "- How did using **class weights** affect training stability and final performance?\n",
        "\n",
        "### 2. Model Performance and Error Analysis\n",
        "*Focus on your MLP and LSTM implementations*\n",
        "\n",
        "- Which of your two models **generalized better** to the test set? Provide evidence from your metrics.\n",
        "- Which **sentiment class** was most frequently misclassified? Propose reasons for this pattern.\n",
        "\n",
        "### 3. Cross-Model Comparison\n",
        "*Compare all six models: MLP, RNN, LSTM, GRU, BERT, GPT*\n",
        "\n",
        "- How did **mean-pooled FastText embeddings** limit the MLP compared to sequence-based models?\n",
        "- What advantage did the LSTM's **sequential processing** provide over the MLP?\n",
        "- Did **fine-tuned LLMs** (BERT/GPT) outperform classical baselines? Explain the performance gap in terms of pretraining and contextual representations.\n",
        "- **Rank all six models** by test performance. What architectural or representational factors explain the ranking?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e68d2d95",
      "metadata": {
        "id": "e68d2d95"
      },
      "source": [
        "## AI Use Disclosure **(5 points)**\n",
        "\n",
        "Complete the **AI Use Disclosure** section in `open_questions.ipynb`. This item is graded separately.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83029649",
      "metadata": {
        "id": "83029649"
      },
      "source": [
        "## Deliverables\n",
        "\n",
        "You must submit the following files:\n",
        "\n",
        "1. `train_sentiment_mlp_classifier.py`  \n",
        "   Implementation of **Task 1** using an MLP with **mean-pooled FastText sentence embeddings**.\n",
        "\n",
        "2. `train_sentiment_lstm_classifier.py`  \n",
        "   Implementation of **Task 2** using an LSTM with **padded/truncated FastText word vectors** (32 tokens per sentence).\n",
        "\n",
        "3. `outputs/` containing PNGs for loss/accuracy/F1 curves and confusion matrices for **all models you ran** (MLP, LSTM, RNN, GRU, BERT, GPT).\n",
        "\n",
        "4. `open_questions.ipynb` and `open_questions.html`  \n",
        "   Your written responses to the **open-ended questions** related to modeling choices, performance comparisons, and reflections. The HTML must include the **plots embedded in the notebook output**, plus your **AI Use Disclosure**.\n",
        "\n",
        "Submission Instructions\n",
        "\n",
        "- Submit `open_questions.html` to **Canvas**.\n",
        "- Push **all `.py`, `.ipynb`, `.html`, and `outputs/` files** to your **GitHub repository**.\n",
        "- Make sure the `.html` file contains **both code and output** so it can be viewed without rerunning the notebook.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}