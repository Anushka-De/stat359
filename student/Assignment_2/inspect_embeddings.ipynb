{
  "cells": [
    {
      "cell_type": "raw",
      "id": "5f68e4d0",
      "metadata": {
        "id": "5f68e4d0"
      },
      "source": [
        "---\n",
        "title: \"Assignment 2: Inspecting and Comparing Embeddings\"\n",
        "format:\n",
        "  html:\n",
        "    toc: true\n",
        "    toc-title: Contents\n",
        "    toc-depth: 4\n",
        "    self-contained: true\n",
        "    number-sections: false\n",
        "jupyter: python3\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8bx02Dk0h-A"
      },
      "source": [
        "*Use this notebook to complete the sentence similarity and embedding visualization tasks.*\n"
      ],
      "id": "S8bx02Dk0h-A"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Anushka-De/stat359.git\n",
        "\n"
      ],
      "metadata": {
        "id": "9ub46YaI0neU",
        "outputId": "c8c4d229-df0d-4edb-9c0e-4e900660d11b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "9ub46YaI0neU",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stat359'...\n",
            "remote: Enumerating objects: 100, done.\u001b[K\n",
            "remote: Counting objects: 100% (49/49), done.\u001b[K\n",
            "remote: Compressing objects: 100% (34/34), done.\u001b[K\n",
            "remote: Total 100 (delta 36), reused 16 (delta 15), pack-reused 51 (from 1)\u001b[K\n",
            "Receiving objects: 100% (100/100), 999.00 KiB | 3.87 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd stat359/student/Assignment_2\n",
        "!ls\n"
      ],
      "metadata": {
        "id": "T9o62Kje05xT",
        "outputId": "b51e6db7-bf1f-4440-a740-bed7fb42f49f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "T9o62Kje05xT",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stat359/stat359/student/Assignment_2\n",
            "data.py\t\t\t  handout.html\t\t      pytorch_train_word2vec.py\n",
            "download_gensim_model.py  inspect_embeddings.ipynb    README.md\n",
            "gensim_train_word2vec.py  pytorch_show_embeddings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy pandas gensim torch scikit-learn matplotlib ipywidgets nltk tqdm datasets\n"
      ],
      "metadata": {
        "id": "RF63TlTK1AZD"
      },
      "id": "RF63TlTK1AZD",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python data.py\n"
      ],
      "metadata": {
        "id": "c-8hyCWL066E",
        "outputId": "386dd3c1-5bae-41e2-87db-01cb054f932d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "c-8hyCWL066E",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences: 1701\n",
            "First sample: ['anarchism', 'originated', 'as', 'a', 'term', 'of', 'abuse', 'first', 'used', 'against', 'early', 'working', 'class', 'radicals', 'including', 'the', 'diggers', 'of', 'the', 'english']\n",
            "Top 10 most common words: [('the', 1061396), ('of', 593677), ('and', 416629), ('one', 411764), ('in', 372201), ('a', 325873), ('to', 316376), ('zero', 264975), ('nine', 250430), ('two', 192644)]\n",
            "Vocab size: 253854\n",
            "Number of skip-gram pairs (first 5 sentences): 199970\n",
            "Sample skip-gram pairs:\n",
            "   center  context\n",
            "0       0        1\n",
            "1       0        2\n",
            "2       1        0\n",
            "3       1        2\n",
            "4       1        3\n",
            "Processed data saved to processed_data.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZyhE1aeAXkS",
        "outputId": "06c259df-de8a-4f8e-d73e-09b1234c4429"
      },
      "id": "fZyhE1aeAXkS",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.py                   handout.html                pytorch_train_word2vec.py\n",
            "download_gensim_model.py  inspect_embeddings.ipynb    README.md\n",
            "gensim_train_word2vec.py  pytorch_show_embeddings.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pytorch_train_word2vec.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JJLMH8jFhBF",
        "outputId": "6b3c437f-1825-4463-8705-de183bc189f2"
      },
      "id": "0JJLMH8jFhBF",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/stat359/stat359/student/Assignment_2/pytorch_train_word2vec.py\", line 27, in <module>\n",
            "    with open('word2vec_embeddings.pkl', 'rb') as f:\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'word2vec_embeddings.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrZXDjqM0h-A"
      },
      "source": [
        "## AI Use Disclosure (Required)\n",
        "\n",
        "If you used any AI-enabled tools (e.g., ChatGPT, GitHub Copilot, Claude, or other LLM assistants) while working on this assignment, you must disclose that use here. The goal is transparency-not punishment.\n",
        "\n",
        "In your disclosure, briefly include:\n",
        "- **Tool(s) used:** (name + version if known)\n",
        "- **How you used them:** (e.g., concept explanation, debugging, drafting code, rewriting text)\n",
        "- **What you verified yourself:** (e.g., reran the notebook, checked outputs/plots, checked shapes, read documentation)\n",
        "- **What you did *not* use AI for (if applicable):** (optional)\n",
        "\n",
        "You are responsible for the correctness of your submission, even if AI suggested code or explanations.\n",
        "\n",
        "#### <font color=\"red\">Write your disclosure here.</font>\n"
      ],
      "id": "RrZXDjqM0h-A"
    },
    {
      "cell_type": "markdown",
      "id": "0f9b62d5",
      "metadata": {
        "id": "0f9b62d5"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}